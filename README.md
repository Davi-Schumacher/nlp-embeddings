# Natural Language Processing - Categorizing Text with Pre-Trained Word Embeddings

In this project, I build a model that categorizes news articles into one of five topics. This method uses word embeddings generated from a model trained on Google News. Each word in every document is converted from a text string to a high dimensional numeric representation, and then fed into a classification model. I will try multiple classification models and hopefully even compare on other datasets and embeddings. Perhaps I may even dabble in some transfer learning.

The general outline of my project looks something like this:

![project outline](https://github.com/Davi-Schumacher/nlp-embeddings/blob/master/NLP%20TL%20News%20Cat.jpg)
