{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which is better for news article classification: Naive Bayes using Count Vectorizer or Logistic Regression using word vectors from a model trained on Google News?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google has pretrained a neural network on news articles. We can extract the word vectors, or word embeddings, that the model has learned and use them to train our own model. Let's load in the model here. It is relatively large so it will take a minute to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    './GoogleNews-vectors-negative300.bin', \n",
    "    binary=True\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to load in the text from the news articles that we want to categorize. If we use Scikit Learn's `load_files` function from `sklearn.datasets`, the data and categories will be automatically loaded, so long as the text files are in properly labeled folders.\n",
    "\n",
    "The `news` variable will store both data and target labels, each of which can be accessed by calling `news.data` and `news.target`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = load_files(\n",
    "    './bbc/', \n",
    "    encoding='utf-8',\n",
    "    decode_error='ignore',\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display a few sentences of one of the articles to get an idea of what they look like, and see what the target labels look like as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_n_sentences(article:str, n):\n",
    "    \"Returns the first n sentences in an article, or None if that number of sentences does not exist\"\n",
    "    first_n = ''\n",
    "    period_counter = 0\n",
    "    for character in article:\n",
    "        first_n += character\n",
    "        if character == '.':\n",
    "            period_counter += 1\n",
    "        if period_counter == n:\n",
    "            return first_n\n",
    "    print(f'There are not {n} sentences in this article')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UK house prices dip in November\\n\\nUK house prices dipped slightly in November, the Office of the Deputy Prime Minister (ODPM) has said.\\n\\nThe average house price fell marginally to £180,226, from £180,444 in October. Recent evidence has suggested that the UK housing market is slowing after interest rate increases, and economists forecast a drop in prices during 2005.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_n_sentences(news.data[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Collins named UK Athletics chief\\n\\nUK Athletics has ended its search for a new performance director by appointing psychologist Dave Collins.\\n\\nCollins, who worked with the British teams at the 2000 and 2004 Olympics, takes over from Max Jones. Six candidates were interviewed for the job, including Denise Lewis' coach Charles van Commenee and former British triple jumper Keith Connor.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_n_sentences(news.data[1000], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business', 'entertainment', 'politics', 'sport', 'tech']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes can take counts of words and generate a model that looks at condtitional class probabilities. In this case, the classes correspond to the five categories of news. Let's start with Naive Bayes since it is quick to prepare. We can use Scikit Learn's `Pipeline` class to easily pass the data through the counting and fitting steps of the Naive Bayes modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_classification(clf: Pipeline, train_data, test_data, train_target, test_target):\n",
    "    \"Helper function wrapping the Pipeline, courtesy of Brian Spiering\"\n",
    "    clf.fit(train_data, train_target) \n",
    "    predicted = clf.predict(test_data)\n",
    "    accuracy = np.mean(predicted==test_target)\n",
    "    print(f\"The accuracy on the test data is {accuracy:.2%}\")\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([('vect', CountVectorizer()),\n",
    "                ('clf', MultinomialNB())])\n",
    "nb_scores = cross_val_score(clf, news.data, news.target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 97.57% (+/- 1.52%)\n"
     ]
    }
   ],
   "source": [
    "print(f'Naive Bayes Accuracy: {100*nb_scores.mean():0.2f}% (+/- {100*nb_scores.std() * 2:0.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is already doing a great job, predicting close to 98%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize and remove punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is helpful to make things easy for the model, which is why we will clean and tokenize the text. The `Spacy` library does a great job of tokenizing, or separating out individual words. This process counts punctuation characters and numbers as tokens, so we can follow up with a very basic regular expression substitution that removes these. Removing punctuation may not always be useful, like in the case of sentiment analysis where punctuation may add additional meaning or emphasis. In our case, punctuation will likely not give any clues to the topic of the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def tokenize_bbc(text_data):\n",
    "    \"Tokenize BBC news articles and remove punctuation and digits\"\n",
    "    clean_text = list()\n",
    "    for text_chunk in text_data:\n",
    "        doc = nlp(text_chunk)\n",
    "        clean = ' '.join([token.text for token in doc])\n",
    "        clean = re.sub('[\\\\n\\.\\,\\(\\)\\'\\\"\\-\\:\\;\\&\\#\\/0-9]', '', clean)\n",
    "        clean_text.append(clean)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.data = tokenize_bbc(news.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the unique words in the corpus and see how many match up with the model vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to use pre-trained word vectors to train a classification model. If none of the words in our articles match up with words in the pre-trained model, then this effort will be for nothing. This next step checks to make sure we are capturing enough of the words to have good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unique_words(text:list)->set: \n",
    "    word_set = set()\n",
    "    for word_list in text:\n",
    "        word_set = word_set | set(word_list)\n",
    "    return word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_matched_vocab(articles:list, model:gensim):\n",
    "    data_vocab = find_unique_words([article.split() for article in articles])  # Vocabulary of the dataset\n",
    "    model_vocab = set(model.vocab.keys())  # Vocabulary of the Google model\n",
    "    matched_vocab = data_vocab & model_vocab  # Intersecting vocabulary\n",
    "    print(f'{len(matched_vocab) * 100 / len(data_vocab) : .2f}% of the dataset vocabulary has been matched')\n",
    "    return matched_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97.00% of the dataset vocabulary has been matched\n"
     ]
    }
   ],
   "source": [
    "matched_vocab = calculate_matched_vocab(news.data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert words to embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we create a dictionary that allows us to look up the word embedding for any word. We choose to only include matched words, since those are the only ones that will be used. Then we convert each word in each article to its corresponding word vector. Finally we save our converted embedded text so we do not have to repeat these intial preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dict = {word:model.get_vector(word) for word in matched_vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_vector(data, embed_dict, matched_vocab):\n",
    "    \"Converts string tokens to word vectors using an embedding dictionary and a set of intersecting vocabulary.\"\n",
    "    embedded_text = list()\n",
    "    for article in data:\n",
    "        embedded_text.append(\n",
    "            np.array([embed_dict[word] for word in article.strip().split() if word in matched_vocab])\n",
    "        )\n",
    "    return embedded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_text = string_to_vector(news.data, embed_dict, matched_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the minimum word article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using regression, our inputs must all be the same length. To ensure this, we can find the article with the smallest number of words and then subset all other articles by that length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrink_to_smallest(embedded_text):\n",
    "    \"Shrinks all embedded text documents to match the minimum length document\"\n",
    "    min_length = np.min([article.shape[0] for article in embedded_text])\n",
    "    embedded_text = [article[:min_length] for article in embedded_text]\n",
    "    return embedded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_text = shrink_to_smallest(embedded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save our work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are done pre-processing, we should save our work. We don't want to have to repeat all these steps if we just want to tune or re-run the model in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./tmp/bbc_text_embed_converted.npy', embedded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_text = np.load('./tmp/bbc_text_embed_converted.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can average the word embeddings to give a notion of meaning to each article and then fit a logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_average_vectors(embedded_text):\n",
    "    \"Calculate the average of the word embeddings for each text in a corpus\"\n",
    "    avg_embed_text = list()\n",
    "    for article in embedded_text:\n",
    "        avg_embed_text.append(np.sum([word for word in article], axis=0) / len(article))\n",
    "    return np.array(avg_embed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_embed_text = create_average_vectors(embedded_text)\n",
    "clf = lr = LogisticRegression(C=100)\n",
    "lr_scores = cross_val_score(clf, avg_embed_text, news.target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 97.71% (+/- 1.62%)\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic Regression Accuracy: {100*lr_scores.mean():0.2f}% (+/- {100*lr_scores.std() * 2:0.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat with newsgroup data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models did really well on the news articles, but I wonder how we would do on a different data set. There is a newsgroup data set that has online postings on various topics. The original data set has more categories, but I made my own aggregate categories (anything having to do with religion was put into the religion folder, etc.) and made sure there were close to equal amounts of posts in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './newsgroups/'\n",
    "boards = load_files(\n",
    "    data_path, \n",
    "    encoding='utf-8',\n",
    "    decode_error='ignore',\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['computer', 'politics', 'recreation', 'religion', 'science']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boards.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenization process is slightly different for the newsgroup data, mainly because the `Spacy` tokenizer doesn't seem to do as good a job at separating the much less nicely formatted text. We need to replace punctuation with spaces first so `Spacy` can do a better job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_newsgroup(text_data):\n",
    "    \"Tokenize newsgroup posts\"\n",
    "    clean_text = list()\n",
    "    for text_chunk in text_data:\n",
    "        text_chunk = re.sub('[\\\\n\\.\\,\\(\\)\\'\\\"\\-\\:\\;\\&\\#\\!\\*\\<\\>\\@\\^\\`\\~\\|\\\\\\$\\/0-9]', ' ', text_chunk)\n",
    "        doc = nlp(text_chunk)\n",
    "        clean = ' '.join([token.text.strip() for token in doc if len(token) > 1])\n",
    "        clean_text.append(clean)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Path: cantaloupe.srv.cs.cmu.edu!magnesium.club.cc.cmu.edu!pitt.edu!zaphod.mps.ohio-state.edu!howland.reston.ans.net!gatech!emory!athena!aisun3.ai.uga.edu!mcovingt\\nFrom: mcovingt@aisun3.ai.uga.edu (Michael Covington)\\nNewsgroups: sci.med\\nSubject: Re: Any info. on Vasomotor Rhinitis\\nMessage-ID: <C5t573.L18@athena.cs.uga.edu>\\nDate: 21 Apr 93 00:25:51 GMT\\nReferences: <1r1t1a$njq@europa.eng.gtefsd.com>\\nSender: usenet@athena.cs.uga.edu\\nOrganization: AI Programs, University of Georgia, Athens\\nLines: 15\\nNntp-Posting-Host: aisun3.ai.uga.edu\\n\\n(Disclaimer: I'm a sufferer, not a doctor.)\\n\\nI'm not sure there's a really sharp distinction between allergic and\\nvasomotor rhinitis.  Basically, vasomotor rhinitis means your nose is\\nstuffy when it has no reason to be (not even an identifiable allergy).\\n\\nDecongestants and steroid sprays work for vasomotor rhinitis.  Also,\\nI can get surprising relief from purely superficial measures such as\\nsaline moisturizing spray and moisturizing gel.\\n\\n-- \\n:-  Michael A. Covington, Associate Research Scientist        :    *****\\n:-  Artificial Intelligence Programs      mcovingt@ai.uga.edu :  *********\\n:-  The University of Georgia              phone 706 542-0358 :   *  *  *\\n:-  Athens, Georgia 30602-7415 U.S.A.     amateur radio N4TMI :  ** *** **  <><\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boards.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boards.data = tokenize_newsgroup(boards.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Path cantaloupe srv cs cmu edu magnesium club cc cmu edu pitt edu zaphod mps ohio state edu howland reston ans net gatech emory athena aisun ai uga edu mcovingt From mcovingt aisun ai uga edu Michael Covington Newsgroups sci med Subject Re Any info on Vasomotor Rhinitis Message ID    athena cs uga edu Date  Apr  GMT References  njq europa eng gtefsd com Sender usenet athena cs uga edu Organization AI Programs University of Georgia Athens Lines  Nntp Posting Host aisun ai uga edu  Disclaimer sufferer not doctor  not sure there really sharp distinction between allergic and vasomotor rhinitis  Basically vasomotor rhinitis means your nose is stuffy when it has no reason to be not even an identifiable allergy  Decongestants and steroid sprays work for vasomotor rhinitis  Also can get surprising relief from purely superficial measures such as saline moisturizing spray and moisturizing gel  Michael Covington Associate Research Scientist  Artificial Intelligence Programs  mcovingt ai uga edu  The University of Georgia  phone  Athens Georgia   amateur radio TMI '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boards.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Naive Bayes first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([('vect', CountVectorizer()),\n",
    "                ('clf', MultinomialNB())])\n",
    "nb_scores_2 = cross_val_score(clf, boards.data, boards.target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 95.88% (+/- 0.99%)\n"
     ]
    }
   ],
   "source": [
    "print(f'Naive Bayes Accuracy: {100*nb_scores_2.mean():0.2f}% (+/- {100*nb_scores_2.std() * 2:0.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is doing slightly worse in this case. For logistic regression, let's match the vocabulary and repeat the modeling steps from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60.31% of the dataset vocabulary has been matched\n"
     ]
    }
   ],
   "source": [
    "matched_vocab_2 = calculate_matched_vocab(boards.data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dict_2 = {word:model.get_vector(word) for word in matched_vocab_2}\n",
    "embedded_text_2 = string_to_vector(boards.data, embed_dict_2, matched_vocab_2)\n",
    "embedded_text_2 = shrink_to_smallest(embedded_text_2)\n",
    "np.save('./tmp/newsgroup_text_embed_converted.npy', embedded_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_text_2 = np.load('./tmp/newsgroup_text_embed_converted.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_embed_text_2 = create_average_vectors(embedded_text_2)\n",
    "clf_2 = LogisticRegression(C=100)\n",
    "lr_scores_2 = cross_val_score(clf_2, avg_embed_text_2, boards.target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newsgroup Logistic Regression Accuracy: 97.63% (+/- 0.89%)\n"
     ]
    }
   ],
   "source": [
    "print(f'Newsgroup Logistic Regression Accuracy: {100*lr_scores_2.mean():0.2f}% (+/- {100*lr_scores_2.std() * 2:0.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the logistic regression method is more robust, seeing as how it has a similiar average accuracy on both data sets. The variance in accuracy dropped in this round, likely because there was more data in this second try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why always 98%? Let's model some random data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm starting to get suspicious that the logistic regression is doing so well, so I am going to generate some random text files and see how well the approach works on them. I will start by loading in the `words.txt` file which is a list of 466,000 English words. Then I will randomly sample it 1000 times, each time grabbing 100 words with replacement, and assign each 'text file' a random category. At that point we can use the same steps as before to predict the categories and see how well we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vocab = set(model.vocab.keys())\n",
    "with open('./words.txt') as f:\n",
    "    words_list = f.readlines()\n",
    "words_list = [word.lower().replace('\\n','') for word in words_list if word.lower().replace('\\n','') in model_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = list(), list()\n",
    "for i in range(1000):\n",
    "    X.append(' '.join(np.random.choice(words_list, 100)))\n",
    "    y.append(np.random.choice([i for i in range(5)], 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100.00% of the dataset vocabulary has been matched\n"
     ]
    }
   ],
   "source": [
    "matched_vocab_3 = calculate_matched_vocab(X, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dict_3 = {word:model.get_vector(word) for word in matched_vocab_3}\n",
    "embedded_text_3 = string_to_vector(X, embed_dict_3, matched_vocab_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_embed_text_3 = create_average_vectors(embedded_text_3)\n",
    "clf_3 = LogisticRegression(C=100)\n",
    "lr_scores_3 = cross_val_score(clf_3, avg_embed_text_3, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy on Random Data: 22.00% (+/- 9.56%)\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic Regression Accuracy on Random Data: {100*lr_scores_3.mean():0.2f}% (+/- {100*lr_scores_3.std() * 2:0.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the approach is not broken, it is just working very well on the large data sets. In the next section we will cut down the number of training samples and figure out whether Naive Bayes or Logistic Regression works better in the small data regime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
